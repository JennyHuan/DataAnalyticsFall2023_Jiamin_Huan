# Lab3
# Heatmap(), image() and hierarchical clustering example
# creating a matrix data with random numbers
# and plotting the matrix using the image() function
# you will see there, it does not have a real pattern in the plot.
set.seed(12345)
help(par)
# par can be used to set or query graphical parameters.
# Parameters can be set by specifying them as arguments
# to par in tag = value form, or by passing them as a list of tagged values.
par(mar = rep(0.2,4))
data_Matrix <-matrix(rnorm(400), nrow = 40)
image(1:10, 1:40, t(data_Matrix)[,nrow(data_Matrix):1])
help("heatmap")
help(rep)
par(mar=rep(0.2,4))
heatmap(data_Matrix)
# When we run the heatmap() here, we get the dendrograms printed on the
# both columns and the rows and still there is no real immerging pattern that is
# interesting to us,
# it is because there is no real interesting pattern underlying in the data we generated.
help("rbinom")
set.seed(678910)
for(i in 1:40){
# flipping a coin and getting the data
coin_Flip <- rbinom(1, size = 1, prob = 0.5)
# if the coin is "Heads", add a common pattern to that row,
if(coin_Flip){
data_Matrix[i, ] <- data_Matrix[i, ] + rep(c(0,3), each =5)
}
}
# during the coin flip, if is it turn out to be one
# (true), then, just added a pattern to my data in a
# way that the five of the columns have a mean
# of zero and others have mean of three.
par(mar= rep(0.2, 4))
image(1:10, 1:40, t(data_Matrix)[, nrow(data_Matrix):1])
par(mar=rep(0.2, 4))
heatmap(data_Matrix)
hh <- hclust(dist(data_Matrix))
data_Matrix_ordered <- data_Matrix[hh$order,]
par(mfrow = c(1,3))
image(t(data_Matrix_ordered)[, nrow(data_Matrix_ordered):1])
plot(rowMeans(data_Matrix_ordered), 40:1, , xlab = "The Row Mean", ylab = "Row", pch =19)
plot(rowMeans(data_Matrix_ordered), xlab = "Column", ylab = "Column Mean", pch =19)
# kmeans 1
#fragment
set.seed(123)
sim.xy <- function(n, mean, sd) cbind(rnorm(n, mean[1], sd[1]),rnorm(n, mean[2],sd[2]))
# generate three clouds of points, well separated in the 2D plane
xy <- rbind(sim.xy(100, c(0,0), c(.2,.2)),sim.xy(100, c(2.5,0), c(.4,.2)),sim.xy(100, c(1.25,.5), c(.3,.2)))
xy[1,] <- c(0,2)     # convert 1st obs. to an outlying value
#
km3 <- kmeans(xy, 3) # ask for three clusters
plot(xy, col=km3$cluster)
cex=2.0
points(km3$centers, pch=3)
#
km4 <- kmeans(xy, 4) # ask for four clusters
cex=1.0
plot(xy, col=km4$cluster)
cex=2.0
points(km4$centers, pch=3)
# kmeans 2
data("iris")
iris.dist <- dist(iris[, -5])
iris.mds <- cmdscale(iris.dist)
# iris$Species is the 5th column
c.chars <- c("*", "o", "+")[as.integer(iris$Species)]
# iris$Species is the 5th column
# KMEANSRESULT is the variable you used in your kmeans lab assignment for the return variable.
a.cols <- rainbow(3)[KMEANSRESULT$cluster]
# iris$Species is the 5th column
# KMEANSRESULT is the variable you used in your kmeans lab assignment for the return variable.
a.cols <- rainbow(3)[km4$cluster]
plot(iris.mds, col = a.cols, pch = c.chars, xlab = "X", ylab = "Y")
